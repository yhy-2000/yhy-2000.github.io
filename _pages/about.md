---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<span class='anchor' id='about-me'></span>
<span style="font-style: italic; color: #6a994e; font-size: 16px;">Life is short, just have fun.</span> 🤪



# 💃🏻 About Me

- 🎓 I am a **Ph.D. candidate** at the [Gaoling School of Artificial Intelligence](https://ai.ruc.edu.cn/), [Renmin University of China](https://www.ruc.edu.cn/), supervised by Prof. [Zhicheng Dou](http://playbigdata.ruc.edu.cn/dou) and Prof. [Ji-Rong Wen](https://scholar.google.com/citations?user=tbxCHJgAAAAJ).  
- 🔬 Currently, I am a **research intern** at **Beijing Academy of Artificial Intelligence (BAAI)**, mentored by [Zheng Liu](https://zhengliu101.github.io/). I sincerely appreciate their meticulous and insightful guidance~ 
- 🎓 I received my bachelor's degree from **Nankai University** in 2022.  
-  **Research Interests**: <span style="color:#c1121f">Retrieval-augmented generation</span>, <span style="color:#c1121f">Multi-modal retrieval</span>, <span style="color:#c1121f">Long video understanding</span>  

---

# 📢 News

- **[2025.09]**: [**MomentSeeker**] was accepted at **NIPS 2025** 🎉🎉 Thanks to all co-authors!!

- **[2025.06]**: Starting this September, I’ll be a visiting student at 🇮🇹**University of Trento**, supervised by [Prof. Dr. Nicu Sebe](https://disi.unitn.it/~sebe/). Looking forward to new collaborations and challenges! 🚀

- **[2025.06]**: Released [**VideoDeepResearch**](https://arxiv.org/pdf/2506.10821), a novel framework combining a text-only LLM and a multi-modal toolkit to beat SOTA MLLMs.  🔗 [Code on GitHub](https://github.com/yhy-2000/VideoDeepResearch)

- **[2025.03]**: Released [**MemVid**](https://arxiv.org/abs/2503.09149), a memory-enhanced RAG framework for long video understanding.

- **[2025.03]**: Paper [**OmniGen**](https://arxiv.org/abs/2409.11340) accepted at **CVPR 2025** 🎉

- **[2025.02]**: Released [**MomentSeeker**](https://arxiv.org/abs/2502.12558), a task-oriented benchmark for long-video moment retrieval.

- **[2024.11]**: [**FineRAG**](https://aclanthology.org/2025.coling-main.741/) accepted at **COLING 2024** 🥳

- **[2023.08]**: [**VILE**](https://dl.acm.org/doi/10.1145/3583780.3615107) accepted at **CIKM 2023** 🥳

---

# 🎓 Education

### - Renmin University of China  (2022.09 – 2027.06 (Expected)) 
- **Ph.D. in Artificial Intelligence**, Supervisor: Prof. Zhicheng Dou, Prof. Ji-Rong Wen  
- GPA: **3.87/4.0**, Key Courses: Intelligent Information Retrieval (A), Machine Learning (A)

###  - Nankai University  (2018.09 – 2022.06) 
- **B.S. in Computer Science**, GPA: **91.64/100**, Rank: **2/116**
- CET-6: 538, CET-4: 585

---

# 📚 Publications


### - **VideoDeepResearch: Long Video Understanding With Agentic Tool Using** | [Paper]([https://arxiv.org/abs/2503.09149](https://arxiv.org/pdf/2506.10821)) | [GitHub](https://github.com/yhy-2000/VideoDeepResearch) | *Preprint*

**H Yuan**, Z Liu, J Zhou, H Qian, JR Wen, Z Dou

> Proposes an agentic framework for long video understanding that leverages a text-only large reasoning model combined with a modular multi-modal toolkit. Achieves superior performance over state-of-the-art open-source and proprietary MLLMs, including GPT-4o, Qwen2.5-VL, and others, across a wide range of long video understanding benchmarks.


### - **MemVid: Memory-enhanced Retrieval Augmentation for Long Video Understanding**  | [Paper](https://arxiv.org/abs/2503.09149) | *Preprint*
**H Yuan**, Z Liu, M Qin, H Qian, Y Shu, Z Dou, JR Wen  
> Tackles query-less long-video understanding with a memorizing-reasoning-retrieving-focusing pipeline inspired by human memory.

---

### - **MomentSeeker: A Comprehensive Benchmark for Long Video Moment Retrieval**  | [Paper](https://arxiv.org/abs/2502.12558) | *Preprint*
**H Yuan**, J Ni, Y Wang, J Zhou, Z Liang, Z Liu, Z Cao, Z Dou, JR Wen  
> Introduces a benchmark with 500s+ videos and diverse tasks; includes an MLLM retriever fine-tuned on synthetic data.

---

### - **OmniGen: Unified Image Generation**  | [Paper](https://arxiv.org/abs/2409.11340) | *CVPR 2025*  
S Xiao*, Y Wang*, J Zhou*, **H Yuan***, X Xing, R Yan, S Wang, T Huang, Z Liu  
> A unified diffusion model that handles text-to-image, image editing, and conditional generation via a simple E2E architecture.

---

### - **FineRAG: Fine-grained Retrieval-Augmented Text-to-Image Generation**  | [Paper](https://aclanthology.org/2025.coling-main.741/) | *COLING 2024*  
**H Yuan**, Z Zhao, S Wang, S Xiao, M Ni, Z Liu, Z Dou  
> Breaks the RAG pipeline into 4 stages: query decomposition, candidate selection, retrieval-augmented diffusion, and self-reflection.

---

### - **VILE: Block-Aware Visual Enhanced Document Retrieval** | [Paper](https://dl.acm.org/doi/10.1145/3583780.3615107) | *CIKM 2023*  
**H Yuan**, Z Dou, Y Zhou, Y Guo, JR Wen  
> Proposes a dense retrieval model that fuses visual and textual signals to improve web page understanding.

---

# 💼 Experiences

- *2024.12 – Present*, **Research Intern**, BAAI  
  Supervised by [Zheng Liu](https://zhengliu101.github.io/)

- *2024.02 – 2024.04*, **Research Intern**, Microsoft Research Asia  
  Supervised by [Chenfei Wu](https://chenfei-wu.github.io/) & [Nan Duan](https://nanduan.github.io/)  

---

# 🏆 Competition

- 🥈 **ICPC Asia Shenyang** – Silver Medal  
- 🥉 **ICPC Asia Kunming** – Bronze Medal  
- 🥈 **Mathematical Modeling Contest** – National Second Prize

---

# 🎖 Scholarships

- 🥇 First-Class Scholarship, Gaoling School of AI – *2022.12*  
- 🥇 First-Class Scholarship (Top 5%), Nankai University – *2021.12*, *2020.12*  
- 🏅 **National Scholarship** (Top 1.2%), Nankai University – *2019.12*
